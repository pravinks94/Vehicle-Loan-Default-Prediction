{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "\n",
    "#model selection from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "#metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "#pca\n",
    "from sklearn.decomposition import PCA\n",
    "#data_balance\n",
    "from sklearn.utils import resample\n",
    "#warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\krishnaraj\\\\Desktop\\\\Great Learning\\\\Capstone Project\\\\github\\\\CAPSTONE\\\\Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-877804619cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\krishnaraj\\Desktop\\Great Learning\\Capstone Project\\github\\CAPSTONE\\Data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\krishnaraj\\\\Desktop\\\\Great Learning\\\\Capstone Project\\\\github\\\\CAPSTONE\\\\Data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\krishnaraj\\Desktop\\Great Learning\\Capstone Project\\github\\CAPSTONE\\Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['UniqueID','MobileNo_Avl_Flag'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute description"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "• disbursed_amount: Amount of Loan disbursed\n",
    "• asset_cost: Cost of the Asset\n",
    "• ltv: Loan to Value of the asset\n",
    "• branch_id: Branch where the loan was disbursed\n",
    "• supplier_id: Vehicle Dealer where the loan was disbursed\n",
    "• manufacturer_id: Vehicle manufacturer(Hero, Honda, TVS etc.)\n",
    "• Current_pincode_ID: Current pincode of the customer\n",
    "• Date.of.Birth: Date of birth of the customer\n",
    "• Employment.Type: Employment Type of the customer (Salaried/Self Employed)\n",
    "• DisbursalDate: Date of disbursement\n",
    "• State_ID: State of disbursement\n",
    "• Employee_code_ID: Employee of the organization who logged the disbursement\n",
    "• MobileNo_Avl_Flag: if Mobile no. was shared by the customer then flagged as 1\n",
    "• Aadhar_flag: if aadhar was shared by the customer then flagged as 1\n",
    "• PAN_flag: if pan was shared by the customer then flagged as 1\n",
    "• VoterID_flag: if voter was shared by the customer then flagged as 1\n",
    "• Driving_flag: if DL was shared by the customer then flagged as 1\n",
    "• Passport_flag: if passport was shared by the customer then flagged as 1\n",
    "• PERFORM_CNS.SCORE: Bureau Score\n",
    "• PERFORM_CNS.SCORE.DESCRIPTION: Bureau score description\n",
    "• PRI.NO.OF.ACCTS: count of total loans taken by the customer at the time of disbursement\n",
    "• PRI.ACTIVE.ACCTS: count of active loans taken by the customer at the time of disbursement\n",
    "• PRI.OVERDUE.ACCTS: count of default accounts at the time of disbursement\n",
    "• PRI.CURRENT.BALANCE: total Principal outstanding amount of the active loans at the time of disbursement\n",
    "• PRI.SANCTIONED.AMOUNT: total amount that was sanctioned for all the loans at the time of disbursement\n",
    "• PRI.DISBURSED.AMOUNT: total amount that was disbursed for all the loans at the time of disbursement\n",
    "• SEC.NO.OF.ACCTS: count of total loans taken by the customer at the time of disbursement\n",
    "• SEC.ACTIVE.ACCTS: count of active loans taken by the customer at the time of disbursement\n",
    "• SEC.OVERDUE.ACCTS: count of default accounts at the time of disbursement\n",
    "• SEC.CURRENT.BALANCE: total Principal outstanding amount of the active loans at the time of disbursement\n",
    "• SEC.SANCTIONED.AMOUNT: total amount that was sanctioned for all the loans at the time of disbursement\n",
    "• SEC.DISBURSED.AMOUNT: total amount that was disbursed for all the loans at the time of disbursement\n",
    "• PRIMARY.INSTAL.AMT: EMI Amount of the primary loan\n",
    "• SEC.INSTAL.AMT: EMI Amount of the secondary loan\n",
    "• NEW.ACCTS.IN.LAST.SIX.MONTHS: New loans taken by the customer in last 6 months before the disbursment\n",
    "• DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS: Loans defaulted in the last 6 months\n",
    "• AVERAGE.ACCT.AGE: Average loan tenure\n",
    "• CREDIT.HISTORY.LENGTH: Time since first loan\n",
    "• NO.OF_INQUIRIES: Enquries done by the customer for loans\n",
    "• loan_default: Payment default in the first EMI on due date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import missingno\n",
    "\n",
    "missingno.matrix(df,figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_col = ['PERFORM_CNS.SCORE.DESCRIPTION']\n",
    "df[temp_col] = df[temp_col].replace('No Bureau History Available', 0)\n",
    "df[temp_col] = df[temp_col].replace('Not Scored: Sufficient History Not Available',0)\n",
    "df[temp_col] = df[temp_col].replace('Not Scored: Not Enough Info available on the customer',0)\n",
    "df[temp_col] = df[temp_col].replace('Not Scored: No Activity seen on the customer (Inactive)',0) \n",
    "df[temp_col] = df[temp_col].replace('Not Scored: No Updates available in last 36 months',0) \n",
    "df[temp_col] = df[temp_col].replace('Not Scored: Only a Guarantor', 0)\n",
    "df[temp_col] = df[temp_col].replace('Not Scored: More than 50 active Accounts found',0)\n",
    "df[temp_col] = df[temp_col].replace('M-Very High Risk', 1)\n",
    "df[temp_col] = df[temp_col].replace('L-Very High Risk', 1)\n",
    "df[temp_col] = df[temp_col].replace('K-High Risk', 2)\n",
    "df[temp_col] = df[temp_col].replace('J-High Risk', 2)\n",
    "df[temp_col] = df[temp_col].replace('I-Medium Risk', 3)\n",
    "df[temp_col] = df[temp_col].replace('H-Medium Risk', 3)\n",
    "df[temp_col] = df[temp_col].replace('G-Low Risk', 4)\n",
    "df[temp_col] = df[temp_col].replace('F-Low Risk', 4)\n",
    "df[temp_col] = df[temp_col].replace('E-Low Risk', 4)\n",
    "df[temp_col] = df[temp_col].replace('D-Very Low Risk', 5)\n",
    "df[temp_col] = df[temp_col].replace('C-Very Low Risk', 5)\n",
    "df[temp_col] = df[temp_col].replace('B-Very Low Risk', 5)\n",
    "df[temp_col] = df[temp_col].replace('A-Very Low Risk', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employment.Type'].fillna('Others',inplace=True)\n",
    "df['Employment.Type'].value_counts()\n",
    "df['Employment.Type']=df['Employment.Type'].replace({'Self employed':0, 'Salaried':1 ,'Others':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Employment.Type':'Employment_Type'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration(dur):\n",
    "    yrs = int(dur.split(' ')[0].replace('yrs',''))\n",
    "    mon = int(dur.split(' ')[1].replace('mon',''))\n",
    "    return yrs*12+mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Avg_Loan_tenure'] = df['AVERAGE.ACCT.AGE'].apply(duration)\n",
    "df['Time_since_1st_loan'] = df['CREDIT.HISTORY.LENGTH'].apply(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['AVERAGE.ACCT.AGE','CREDIT.HISTORY.LENGTH'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age(dur):\n",
    "    yr = int(dur.split('-')[2])\n",
    "    if yr >=0 and yr<=19:\n",
    "        return yr+2000\n",
    "    else:\n",
    "         return yr+1900\n",
    "\n",
    "df['Date.of.Birth'] = df['Date.of.Birth'].apply(age)\n",
    "df['DisbursalDate'] = df['DisbursalDate'].apply(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age_at_disbursal']=df['DisbursalDate']-df['Date.of.Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.loan_default\n",
    "X=df.drop(\"loan_default\",axis=1)\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "y_pred=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Test set\n",
    "model_score = lr.score(X_test,y_test)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "model_score = lr.score(X_train,y_train)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"precision :\",precision_score(y_test,y_pred),\"\\n\")\n",
    "print(\"f1 score:\",f1_score(y_test,y_pred),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
